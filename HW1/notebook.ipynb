{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ANOVA is a statistical test that can be used to assess the discriminative power of a \\\n",
    "single input variable. Using `f_classif` from `sklearn`, identify the input variables with the \\\n",
    "worst and best discriminative power. Plot their class-conditional probability density \\\n",
    "functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.feature_selection import f_classif\n",
    "from seaborn import kdeplot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Create dataframe from .arff database\n",
    "df = pd.DataFrame(loadarff('./diabetes.arff')[0])\n",
    "df['Outcome'] = df['Outcome'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute variables with lowest/highest discriminative power\n",
    "x = df.drop('Outcome', axis=1) # Everything but the outcome column\n",
    "y_out = df['Outcome'] # Outcome column\n",
    "\n",
    "anova_f_value = f_classif(x, y_out)[0] # Get the f-value only\n",
    "\n",
    "lowest_power_var = x.columns[anova_f_value.argmin()]\n",
    "highest_power_var = x.columns[anova_f_value.argmax()]\n",
    "\n",
    "print(f'''\n",
    "    Input var. with lowest discriminative power: ${lowest_power_var}\n",
    "    Input var. with highest discriminative power: ${highest_power_var}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the class-conditional probability density functions\n",
    "unique_outcomes = df['Outcome'].unique()\n",
    "\n",
    "outcome_subsets = [(df[df['Outcome'] == outcome], outcome) for outcome in unique_outcomes]\n",
    "\n",
    "# Input var. with lowest discriminative power\n",
    "plt.figure(figsize=(10, 6))\n",
    "for subset, outcome_class in outcome_subsets:\n",
    "    kdeplot(subset[lowest_power_var], label=f'Class {outcome_class}')\n",
    "plt.xlabel(lowest_power_var)\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Class')\n",
    "plt.title(f'Class-Conditional Probability Density Function for {lowest_power_var}')\n",
    "plt.show()\n",
    "\n",
    "# Input var. with highest discriminative power\n",
    "plt.figure(figsize=(10, 6))\n",
    "for subset, outcome_class in outcome_subsets:\n",
    "    kdeplot(subset[highest_power_var], label=f'Class {outcome_class}')\n",
    "plt.xlabel(highest_power_var)\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Class')\n",
    "plt.title(f'Class-Conditional Probability Density Function for {highest_power_var}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
